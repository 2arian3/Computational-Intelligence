{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ossZFd6zMv0u",
        "outputId": "f13618a2-1985-403c-ad23-7503238886ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y1vgzPvMeVcXSxDfOlCVia7wsU7p8M6g\n",
            "To: /content/CIFAR10.tar.gz\n",
            "100% 19.8M/19.8M [00:00<00:00, 95.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1Y1vgzPvMeVcXSxDfOlCVia7wsU7p8M6g -O CIFAR10.tar.gz\n",
        "!tar xzf CIFAR10.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK0WXZMfeRjB"
      },
      "source": [
        "Downloading dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVaZrmxRdchB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "DATA_SET_PATH = './CIFAR10'\n",
        "CLASSES = ['airplane', 'automobile', 'bird', 'cat']\n",
        "    \n",
        "INPUT_LAYER_SIZE = 1024\n",
        "HIDDEN_LAYER_SIZE = 16\n",
        "OUTPUT_LAYER_SIZE = len(CLASSES)\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 20\n",
        "LEARNING_RATE = 0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGPAA3UtfQAZ"
      },
      "source": [
        "Importing numpy and matplotlib. <br/>\n",
        "Defining hyperparameters and specifying dataset path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJSS7rw1fDdH"
      },
      "outputs": [],
      "source": [
        "def show_image(img):\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def rgb_to_grayscale(rgb):\n",
        "    return np.uint8(np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]))\n",
        "\n",
        "\n",
        "def read_image(file):\n",
        "    return plt.imread(file)\n",
        "\n",
        "\n",
        "def create_one_hot(arr):\n",
        "    res = np.zeros((arr.size, arr.max() + 1))\n",
        "    res[np.arange(arr.size), arr] = 1\n",
        "    return res\n",
        "\n",
        "\n",
        "def shuffle_data(data, labels):\n",
        "    # Shuffling both of data and labels matrices in the same order\n",
        "    indices = np.arange(len(data))\n",
        "    np.random.shuffle(indices)\n",
        "    return data[indices], labels[indices]\n",
        "\n",
        "\n",
        "def read_data_set():\n",
        "    from os import listdir\n",
        "    \n",
        "    train_data, train_data_labels = [], []\n",
        "    test_data, test_data_labels = [], []\n",
        "    \n",
        "    for data_class in CLASSES:\n",
        "        directory = '{}/train/{}/'.format(DATA_SET_PATH, data_class)\n",
        "        for i in range(len(listdir(directory))):\n",
        "            img = read_image('{}{}'.format(directory, '{}.jpg'.format(str(i).zfill(4))))\n",
        "            train_data.append(img)\n",
        "            train_data_labels.append(CLASSES.index(data_class))\n",
        "    train_data_labels = create_one_hot(np.array(train_data_labels))\n",
        "    \n",
        "    for data_class in CLASSES:\n",
        "        directory = '{}/test/{}/'.format(DATA_SET_PATH, data_class)\n",
        "        for i in range(len(listdir(directory))):\n",
        "            img = read_image('{}{}'.format(directory, '{}.jpg'.format(str(i).zfill(4))))\n",
        "            test_data.append(img)\n",
        "            test_data_labels.append(CLASSES.index(data_class))\n",
        "    test_data_labels = create_one_hot(np.array(test_data_labels))\n",
        "\n",
        "    # Showing two samples of the dataset\n",
        "    show_image(train_data[0])\n",
        "    show_image(test_data[0])\n",
        "    \n",
        "    # Converting rgb images to grayscale images\n",
        "    grayscale_train_data = np.array([rgb_to_grayscale(img) for img in train_data])\n",
        "    grayscale_test_data = np.array([rgb_to_grayscale(img) for img in test_data])\n",
        "    \n",
        "    # Normalizing grayscale images\n",
        "    grayscale_train_data = grayscale_train_data / 255\n",
        "    grayscale_test_data = grayscale_test_data / 255\n",
        "    \n",
        "    # Flatting normalized grayscale images\n",
        "    grayscale_train_data = grayscale_train_data.reshape(-1, INPUT_LAYER_SIZE)\n",
        "    grayscale_test_data = grayscale_test_data.reshape(-1, INPUT_LAYER_SIZE)\n",
        "    \n",
        "    # Shuffling data and labels\n",
        "    grayscale_train_data, train_data_labels = shuffle_data(grayscale_train_data, train_data_labels)\n",
        "    grayscale_test_data, test_data_labels = shuffle_data(grayscale_test_data, test_data_labels)\n",
        "    \n",
        "    return grayscale_train_data, train_data_labels, grayscale_test_data, test_data_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdaJ0Ffmfa-t"
      },
      "source": [
        "## First Part (Reading dataset)\n",
        "Defining some useful functions for reading the data set and doing the preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "JyYivojcfap5",
        "outputId": "b6ef76ac-202c-4f5a-ce74-849daa71a996"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Reading the data set\n",
        "train_data, train_data_labels, test_data, test_data_labels = read_data_set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWF00S1AgbJE"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def derivative_of_sigmoid(x):\n",
        "    sig_x = sigmoid(x)\n",
        "    return (1 - sig_x) * sig_x\n",
        "\n",
        "\n",
        "def random_matrix_generator(rows, cols):\n",
        "    return np.random.randn(rows, cols)\n",
        "\n",
        "\n",
        "def zero_matrix_generator(rows, cols):\n",
        "    return np.zeros((rows, cols))\n",
        "\n",
        "\n",
        "def feed_forward(input_data, weights, biases):\n",
        "    input_data = input_data.reshape(-1, 1)\n",
        "    w0, w1, w2 = weights\n",
        "    b0, b1, b2 = biases\n",
        "\n",
        "    z1 = w0 @ input_data + b0\n",
        "    a1 = sigmoid(z1).reshape(-1, 1)\n",
        "    \n",
        "    z2 = w1 @ a1 + b1\n",
        "    a2 = sigmoid(z2).reshape(-1, 1)\n",
        "    \n",
        "    z3 = w2 @ a2 + b2\n",
        "    a3 = sigmoid(z3).reshape(-1, 1)\n",
        "    \n",
        "    return (a1, a2, a3), (z1, z2, z3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIFeToTCh7a8"
      },
      "source": [
        "## Second Part (Feedforward)\n",
        "Computing network output based on given input and parameters (weights and biases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDKcSXpwiNep",
        "outputId": "54f69fd8-40df-4a23-806b-0ff0ce57c287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing network without training...\n",
            "Accuracy: 22.0%\n"
          ]
        }
      ],
      "source": [
        "def test_network(input_data, labels, weights=None, biases=None):\n",
        "    correct_guesses = 0\n",
        "    input_data_length = len(input_data)\n",
        "    \n",
        "    if weights == None:\n",
        "      weights = (random_matrix_generator(HIDDEN_LAYER_SIZE, INPUT_LAYER_SIZE),\n",
        "               random_matrix_generator(HIDDEN_LAYER_SIZE, HIDDEN_LAYER_SIZE),\n",
        "               random_matrix_generator(OUTPUT_LAYER_SIZE, HIDDEN_LAYER_SIZE))\n",
        "    if biases == None:\n",
        "      biases = (zero_matrix_generator(HIDDEN_LAYER_SIZE, 1),\n",
        "              zero_matrix_generator(HIDDEN_LAYER_SIZE, 1),\n",
        "              zero_matrix_generator(OUTPUT_LAYER_SIZE, 1))\n",
        "\n",
        "    for i in range(input_data_length):\n",
        "        actual_data, _ = feed_forward(input_data[i], weights, biases)\n",
        "        actual_data = np.argmax(actual_data[-1])\n",
        "        desired_data = np.argmax(labels[i])\n",
        "        \n",
        "        # Checking if the network's output is valid or not\n",
        "        if actual_data == desired_data:\n",
        "            correct_guesses += 1\n",
        "    \n",
        "    return correct_guesses / input_data_length\n",
        "\n",
        "print('Testing network without training...')\n",
        "print(f'Accuracy: {test_network(train_data[:200], train_data_labels[:200]) * 100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW55R4YJipOc"
      },
      "source": [
        "## Third Part (Implementing network tutorial based on backpropagation)\n",
        "Defining network training based on non-vectorized backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "d5X2J4tki9VY",
        "outputId": "22b10137-7c7a-4223-871f-2494a810e471"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch1: 54/200 = 27.0%\n",
            "Epoch2: 53/200 = 26.5%\n",
            "Epoch3: 46/200 = 23.0%\n",
            "Epoch4: 40/200 = 20.0%\n",
            "Epoch5: 43/200 = 21.5%\n",
            "Epoch6: 43/200 = 21.5%\n",
            "Epoch7: 45/200 = 22.5%\n",
            "Epoch8: 45/200 = 22.5%\n",
            "Epoch9: 47/200 = 23.5%\n",
            "Epoch10: 53/200 = 26.5%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 151.24999117851257 seconds\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot(x, y, x_label, y_label):\n",
        "    plt.plot(x, y)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def cost_function(actual_data, desired_data):\n",
        "    return np.sum(np.square(actual_data - desired_data))\n",
        "\n",
        "\n",
        "def create_gradient_matrices():\n",
        "    grad_w0 = zero_matrix_generator(HIDDEN_LAYER_SIZE, INPUT_LAYER_SIZE)\n",
        "    grad_w1 = zero_matrix_generator(HIDDEN_LAYER_SIZE, HIDDEN_LAYER_SIZE)\n",
        "    grad_w2 = zero_matrix_generator(OUTPUT_LAYER_SIZE, HIDDEN_LAYER_SIZE)\n",
        "    \n",
        "    grad_a1 = zero_matrix_generator(HIDDEN_LAYER_SIZE, 1)\n",
        "    grad_a2 = zero_matrix_generator(HIDDEN_LAYER_SIZE, 1)\n",
        "    \n",
        "    grad_b0 = zero_matrix_generator(HIDDEN_LAYER_SIZE, 1)\n",
        "    grad_b1 = zero_matrix_generator(HIDDEN_LAYER_SIZE, 1)\n",
        "    grad_b2 = zero_matrix_generator(OUTPUT_LAYER_SIZE, 1)\n",
        "    \n",
        "    grad_w = np.array([grad_w0, grad_w1, grad_w2])\n",
        "    grad_b = np.array([grad_b0, grad_b1, grad_b2])\n",
        "    grad_a = np.array([grad_a1, grad_a2])\n",
        "    \n",
        "    return grad_w, grad_b, grad_a\n",
        "\n",
        "\n",
        "def backpropagation(data, data_label, w, z, a):\n",
        "    data = data.reshape(-1, 1)\n",
        "    data_label = data_label.reshape(-1, 1)\n",
        "    \n",
        "    grad_w, grad_b, grad_a = create_gradient_matrices()\n",
        "    \n",
        "    d_sig_z0 = derivative_of_sigmoid(z[0]).reshape(-1, 1)\n",
        "    d_sig_z1 = derivative_of_sigmoid(z[1]).reshape(-1, 1)\n",
        "    d_sig_z2 = derivative_of_sigmoid(z[2]).reshape(-1, 1)\n",
        "    \n",
        "    # Calculating gradients of parameters in the last layer\n",
        "    for i in range(OUTPUT_LAYER_SIZE):\n",
        "        for j in range(HIDDEN_LAYER_SIZE):\n",
        "            grad_w[2][i][j] = 2 * (a[2][i] - data_label[i]) * d_sig_z2[i] * a[1][j]\n",
        "            \n",
        "    for i in range(OUTPUT_LAYER_SIZE):\n",
        "        grad_b[2][i] = 2 * (a[2][i] - data_label[i]) * d_sig_z2[i]\n",
        "        \n",
        "    for i in range(HIDDEN_LAYER_SIZE):\n",
        "        for j in range(OUTPUT_LAYER_SIZE):\n",
        "            grad_a[1][i] += 2 * (a[2][j] - data_label[j]) * d_sig_z2[j] * w[2][j][i]\n",
        "    \n",
        "    # Calculating gradients of parameters in the second hidden layer      \n",
        "    for i in range(HIDDEN_LAYER_SIZE):\n",
        "        for j in range(HIDDEN_LAYER_SIZE):\n",
        "            grad_w[1][i][j] = grad_a[1][i] * d_sig_z1[i] * a[0][j]\n",
        "            \n",
        "    for i in range(HIDDEN_LAYER_SIZE):\n",
        "        grad_b[1][i] = grad_a[1][i] * d_sig_z1[i]\n",
        "        \n",
        "    for i in range(HIDDEN_LAYER_SIZE):\n",
        "        for j in range(OUTPUT_LAYER_SIZE):\n",
        "            grad_a[0][i] = w[1][j][i] * d_sig_z1[j] * grad_a[1][j]\n",
        "\n",
        "    # Calculating gradients of parameters in the first hidden layer\n",
        "    for i in range(HIDDEN_LAYER_SIZE):\n",
        "        for j in range(INPUT_LAYER_SIZE):\n",
        "            grad_w[0][i][j] = grad_a[0][i] * d_sig_z0[i] * data[j]\n",
        "            \n",
        "    for i in range(HIDDEN_LAYER_SIZE):\n",
        "        grad_b[0][i] = grad_a[0][i] * d_sig_z0[i]\n",
        "    \n",
        "    return grad_w, grad_b, grad_a\n",
        "  \n",
        "\n",
        "def train_network(input_data, input_data_labels, weights, biases, backpropagation_method=backpropagation):\n",
        "    w0, w1, w2 = weights\n",
        "    b0, b1, b2 = biases\n",
        "\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    avg_cost = []\n",
        "    for epoch in range(EPOCHS):\n",
        "        batches, batch_labels = shuffle_data(input_data, input_data_labels)\n",
        "        batches = [batches[i:i + BATCH_SIZE] for i in range(0, len(batches), BATCH_SIZE)]\n",
        "        batch_labels = [batch_labels[i:i + BATCH_SIZE] for i in range(0, len(batch_labels), BATCH_SIZE)]\n",
        "        \n",
        "        cost = 0\n",
        "        correct_guesses = 0\n",
        "        for batch, batch_label in zip(batches, batch_labels):\n",
        "            grad_w, grad_b, grad_a = create_gradient_matrices()\n",
        "            \n",
        "            for image, image_label in zip(batch, batch_label):\n",
        "                a, z = feed_forward(image, (w0, w1, w2), (b0, b1, b2))\n",
        "                w = [w0, w1, w2]\n",
        "\n",
        "                actual_data = np.argmax(a[-1])\n",
        "                desired_data = np.argmax(image_label)\n",
        "                cost += cost_function(a[-1], image_label.reshape(-1, 1))\n",
        "                \n",
        "                # Checking if the network's output is valid or not\n",
        "                if actual_data == desired_data:\n",
        "                    correct_guesses += 1\n",
        "\n",
        "                grad_w_temp, grad_b_temp, grad_a_temp = backpropagation_method(image, image_label, w, z, a)\n",
        "\n",
        "                grad_w += grad_w_temp\n",
        "                grad_b += grad_b_temp\n",
        "                grad_a += grad_a_temp\n",
        "            \n",
        "            # Updating the network's weights based on the average gradients\n",
        "            w0 -= LEARNING_RATE * grad_w[0] / BATCH_SIZE\n",
        "            w1 -= LEARNING_RATE * grad_w[1] / BATCH_SIZE\n",
        "            w2 -= LEARNING_RATE * grad_w[2] / BATCH_SIZE\n",
        "        \n",
        "            # Updating the network's biases based on the average gradients\n",
        "            b0 -= LEARNING_RATE * grad_b[0] / BATCH_SIZE\n",
        "            b1 -= LEARNING_RATE * grad_b[1] / BATCH_SIZE\n",
        "            b2 -= LEARNING_RATE * grad_b[2] / BATCH_SIZE\n",
        "       \n",
        "        avg_cost.append(cost / len(input_data))\n",
        "        print(f'Epoch{epoch + 1}: {correct_guesses}/{len(input_data)} = {correct_guesses/len(input_data) * 100}%') \n",
        "    \n",
        "    print('\\nTraining is finished...')\n",
        "    print(f'Time taken for training: {time.time() - start_time} seconds') \n",
        "    \n",
        "    # Returning the trained parameters and also the average cost\n",
        "    return (w0, w1, w2), (b0, b1, b2), avg_cost\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "weights = (random_matrix_generator(HIDDEN_LAYER_SIZE, INPUT_LAYER_SIZE),\n",
        "               random_matrix_generator(HIDDEN_LAYER_SIZE, HIDDEN_LAYER_SIZE),\n",
        "               random_matrix_generator(OUTPUT_LAYER_SIZE, HIDDEN_LAYER_SIZE))\n",
        "biases = (zero_matrix_generator(HIDDEN_LAYER_SIZE, 1),\n",
        "          zero_matrix_generator(HIDDEN_LAYER_SIZE, 1),\n",
        "          zero_matrix_generator(OUTPUT_LAYER_SIZE, 1))\n",
        "\n",
        "weights, biases, avg_costs = train_network(train_data[:200], train_data_labels[:200], \n",
        "                                            weights, biases, backpropagation_method=backpropagation)\n",
        "\n",
        "plot(range(len(avg_costs)), avg_costs, 'epoch', 'loss') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21i30ddvlLh6"
      },
      "source": [
        "## Fourth Part (Vectorized backpropagation)\n",
        "Implementing vectorized backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "BLudl2UslWwi",
        "outputId": "cecd0100-4fb4-47fb-bf31-81ee78135ac0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch1: 53/200 = 26.5%\n",
            "Epoch2: 46/200 = 23.0%\n",
            "Epoch3: 50/200 = 25.0%\n",
            "Epoch4: 50/200 = 25.0%\n",
            "Epoch5: 65/200 = 32.5%\n",
            "Epoch6: 64/200 = 32.0%\n",
            "Epoch7: 65/200 = 32.5%\n",
            "Epoch8: 71/200 = 35.5%\n",
            "Epoch9: 72/200 = 36.0%\n",
            "Epoch10: 72/200 = 36.0%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 0.7019782066345215 seconds\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def vectorized_backpropagation(data, data_label, w, z, a):\n",
        "    data = data.reshape(-1, 1)\n",
        "    data_label = data_label.reshape(-1, 1)\n",
        "    \n",
        "    grad_w, grad_b, grad_a = create_gradient_matrices()\n",
        "    \n",
        "    d_sig_z0 = derivative_of_sigmoid(z[0]).reshape(-1, 1)\n",
        "    d_sig_z1 = derivative_of_sigmoid(z[1]).reshape(-1, 1)\n",
        "    d_sig_z2 = derivative_of_sigmoid(z[2]).reshape(-1, 1)\n",
        "\n",
        "    # Calculating gradients of parameters in the last layer\n",
        "    grad_w[2] = 2 * d_sig_z2 * (a[2] - data_label) @ a[1].T\n",
        "    grad_b[2] = 2 * d_sig_z2 * (a[2] - data_label)\n",
        "    grad_a[1] = w[2].T @ (2 * d_sig_z2 * (a[2] - data_label))\n",
        "    \n",
        "    # Calculating gradients of parameters in the second hidden layer\n",
        "    grad_w[1] = grad_a[1] * d_sig_z1 @ a[0].T\n",
        "    grad_b[1] = grad_a[1] * d_sig_z1\n",
        "    grad_a[0] = w[1].T @ grad_a[1] * d_sig_z1\n",
        "    \n",
        "    # Calculating gradients of parameters in the first hidden layer\n",
        "    grad_w[0] = grad_a[0] * d_sig_z0 @ data.T\n",
        "    grad_b[0] = grad_a[0] * d_sig_z0\n",
        "\n",
        "    return grad_w, grad_b, grad_a\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "weights = (random_matrix_generator(HIDDEN_LAYER_SIZE, INPUT_LAYER_SIZE),\n",
        "               random_matrix_generator(HIDDEN_LAYER_SIZE, HIDDEN_LAYER_SIZE),\n",
        "               random_matrix_generator(OUTPUT_LAYER_SIZE, HIDDEN_LAYER_SIZE))\n",
        "biases = (zero_matrix_generator(HIDDEN_LAYER_SIZE, 1),\n",
        "          zero_matrix_generator(HIDDEN_LAYER_SIZE, 1),\n",
        "          zero_matrix_generator(OUTPUT_LAYER_SIZE, 1))\n",
        "\n",
        "weights, biases, avg_costs = train_network(train_data[:200], train_data_labels[:200], \n",
        "                                            weights, biases, backpropagation_method=vectorized_backpropagation)\n",
        "\n",
        "plot(range(len(avg_costs)), avg_costs, 'epoch', 'loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le0uyu80loep"
      },
      "source": [
        "We can see a HUGE difference for the time taken for training of the model based on vectorized and non-vectorized backpropagation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-dwZF4AnaU8"
      },
      "source": [
        "Incrementing epochs and rerunning the model with vectorized backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oM6OVlyFnkwR",
        "outputId": "fe1e6a45-b79e-4dec-81ed-c35dc35a2dfd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch1: 52/200 = 26.0%\n",
            "Epoch2: 54/200 = 27.0%\n",
            "Epoch3: 72/200 = 36.0%\n",
            "Epoch4: 64/200 = 32.0%\n",
            "Epoch5: 67/200 = 33.5%\n",
            "Epoch6: 62/200 = 31.0%\n",
            "Epoch7: 68/200 = 34.0%\n",
            "Epoch8: 69/200 = 34.5%\n",
            "Epoch9: 73/200 = 36.5%\n",
            "Epoch10: 79/200 = 39.5%\n",
            "Epoch11: 71/200 = 35.5%\n",
            "Epoch12: 80/200 = 40.0%\n",
            "Epoch13: 74/200 = 37.0%\n",
            "Epoch14: 86/200 = 43.0%\n",
            "Epoch15: 88/200 = 44.0%\n",
            "Epoch16: 83/200 = 41.5%\n",
            "Epoch17: 83/200 = 41.5%\n",
            "Epoch18: 83/200 = 41.5%\n",
            "Epoch19: 83/200 = 41.5%\n",
            "Epoch20: 85/200 = 42.5%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 1.5076947212219238 seconds\n",
            "\n",
            "Round 1 finished...\n",
            "Testing Accuracy for Test Data: 34.625%\n",
            "\n",
            "Epoch1: 81/200 = 40.5%\n",
            "Epoch2: 82/200 = 41.0%\n",
            "Epoch3: 85/200 = 42.5%\n",
            "Epoch4: 82/200 = 41.0%\n",
            "Epoch5: 87/200 = 43.5%\n",
            "Epoch6: 84/200 = 42.0%\n",
            "Epoch7: 88/200 = 44.0%\n",
            "Epoch8: 82/200 = 41.0%\n",
            "Epoch9: 80/200 = 40.0%\n",
            "Epoch10: 85/200 = 42.5%\n",
            "Epoch11: 84/200 = 42.0%\n",
            "Epoch12: 89/200 = 44.5%\n",
            "Epoch13: 90/200 = 45.0%\n",
            "Epoch14: 93/200 = 46.5%\n",
            "Epoch15: 94/200 = 47.0%\n",
            "Epoch16: 96/200 = 48.0%\n",
            "Epoch17: 91/200 = 45.5%\n",
            "Epoch18: 94/200 = 47.0%\n",
            "Epoch19: 95/200 = 47.5%\n",
            "Epoch20: 95/200 = 47.5%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 1.5289885997772217 seconds\n",
            "\n",
            "Round 2 finished...\n",
            "Testing Accuracy for Test Data: 36.625%\n",
            "\n",
            "Epoch1: 94/200 = 47.0%\n",
            "Epoch2: 102/200 = 51.0%\n",
            "Epoch3: 97/200 = 48.5%\n",
            "Epoch4: 93/200 = 46.5%\n",
            "Epoch5: 98/200 = 49.0%\n",
            "Epoch6: 91/200 = 45.5%\n",
            "Epoch7: 91/200 = 45.5%\n",
            "Epoch8: 101/200 = 50.5%\n",
            "Epoch9: 96/200 = 48.0%\n",
            "Epoch10: 93/200 = 46.5%\n",
            "Epoch11: 94/200 = 47.0%\n",
            "Epoch12: 100/200 = 50.0%\n",
            "Epoch13: 100/200 = 50.0%\n",
            "Epoch14: 101/200 = 50.5%\n",
            "Epoch15: 99/200 = 49.5%\n",
            "Epoch16: 99/200 = 49.5%\n",
            "Epoch17: 100/200 = 50.0%\n",
            "Epoch18: 100/200 = 50.0%\n",
            "Epoch19: 98/200 = 49.0%\n",
            "Epoch20: 107/200 = 53.5%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 1.476806879043579 seconds\n",
            "\n",
            "Round 3 finished...\n",
            "Testing Accuracy for Test Data: 36.425000000000004%\n",
            "\n",
            "Epoch1: 98/200 = 49.0%\n",
            "Epoch2: 105/200 = 52.5%\n",
            "Epoch3: 107/200 = 53.5%\n",
            "Epoch4: 100/200 = 50.0%\n",
            "Epoch5: 108/200 = 54.0%\n",
            "Epoch6: 103/200 = 51.5%\n",
            "Epoch7: 108/200 = 54.0%\n",
            "Epoch8: 106/200 = 53.0%\n",
            "Epoch9: 106/200 = 53.0%\n",
            "Epoch10: 107/200 = 53.5%\n",
            "Epoch11: 108/200 = 54.0%\n",
            "Epoch12: 106/200 = 53.0%\n",
            "Epoch13: 110/200 = 55.00000000000001%\n",
            "Epoch14: 107/200 = 53.5%\n",
            "Epoch15: 113/200 = 56.49999999999999%\n",
            "Epoch16: 108/200 = 54.0%\n",
            "Epoch17: 110/200 = 55.00000000000001%\n",
            "Epoch18: 111/200 = 55.50000000000001%\n",
            "Epoch19: 110/200 = 55.00000000000001%\n",
            "Epoch20: 115/200 = 57.49999999999999%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 1.483189344406128 seconds\n",
            "\n",
            "Round 4 finished...\n",
            "Testing Accuracy for Test Data: 37.7%\n",
            "\n",
            "Epoch1: 113/200 = 56.49999999999999%\n",
            "Epoch2: 109/200 = 54.50000000000001%\n",
            "Epoch3: 110/200 = 55.00000000000001%\n",
            "Epoch4: 114/200 = 56.99999999999999%\n",
            "Epoch5: 114/200 = 56.99999999999999%\n",
            "Epoch6: 113/200 = 56.49999999999999%\n",
            "Epoch7: 121/200 = 60.5%\n",
            "Epoch8: 114/200 = 56.99999999999999%\n",
            "Epoch9: 121/200 = 60.5%\n",
            "Epoch10: 118/200 = 59.0%\n",
            "Epoch11: 117/200 = 58.5%\n",
            "Epoch12: 115/200 = 57.49999999999999%\n",
            "Epoch13: 120/200 = 60.0%\n",
            "Epoch14: 116/200 = 57.99999999999999%\n",
            "Epoch15: 117/200 = 58.5%\n",
            "Epoch16: 118/200 = 59.0%\n",
            "Epoch17: 121/200 = 60.5%\n",
            "Epoch18: 119/200 = 59.5%\n",
            "Epoch19: 118/200 = 59.0%\n",
            "Epoch20: 117/200 = 58.5%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 1.440702199935913 seconds\n",
            "\n",
            "Round 5 finished...\n",
            "Testing Accuracy for Test Data: 38.2%\n",
            "\n",
            "Epoch1: 120/200 = 60.0%\n",
            "Epoch2: 118/200 = 59.0%\n",
            "Epoch3: 121/200 = 60.5%\n",
            "Epoch4: 120/200 = 60.0%\n",
            "Epoch5: 125/200 = 62.5%\n",
            "Epoch6: 120/200 = 60.0%\n",
            "Epoch7: 119/200 = 59.5%\n",
            "Epoch8: 129/200 = 64.5%\n",
            "Epoch9: 120/200 = 60.0%\n",
            "Epoch10: 127/200 = 63.5%\n",
            "Epoch11: 133/200 = 66.5%\n",
            "Epoch12: 130/200 = 65.0%\n",
            "Epoch13: 129/200 = 64.5%\n",
            "Epoch14: 130/200 = 65.0%\n",
            "Epoch15: 132/200 = 66.0%\n",
            "Epoch16: 127/200 = 63.5%\n",
            "Epoch17: 131/200 = 65.5%\n",
            "Epoch18: 124/200 = 62.0%\n",
            "Epoch19: 126/200 = 63.0%\n",
            "Epoch20: 124/200 = 62.0%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 1.440112590789795 seconds\n",
            "\n",
            "Round 6 finished...\n",
            "Testing Accuracy for Test Data: 36.35%\n",
            "\n",
            "Epoch1: 122/200 = 61.0%\n",
            "Epoch2: 133/200 = 66.5%\n",
            "Epoch3: 126/200 = 63.0%\n",
            "Epoch4: 131/200 = 65.5%\n",
            "Epoch5: 132/200 = 66.0%\n",
            "Epoch6: 124/200 = 62.0%\n",
            "Epoch7: 133/200 = 66.5%\n",
            "Epoch8: 129/200 = 64.5%\n",
            "Epoch9: 135/200 = 67.5%\n",
            "Epoch10: 130/200 = 65.0%\n",
            "Epoch11: 131/200 = 65.5%\n",
            "Epoch12: 135/200 = 67.5%\n",
            "Epoch13: 128/200 = 64.0%\n",
            "Epoch14: 128/200 = 64.0%\n",
            "Epoch15: 133/200 = 66.5%\n",
            "Epoch16: 132/200 = 66.0%\n",
            "Epoch17: 128/200 = 64.0%\n",
            "Epoch18: 127/200 = 63.5%\n",
            "Epoch19: 127/200 = 63.5%\n",
            "Epoch20: 134/200 = 67.0%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 1.4520227909088135 seconds\n",
            "\n",
            "Round 7 finished...\n",
            "Testing Accuracy for Test Data: 37.225%\n",
            "\n",
            "Epoch1: 129/200 = 64.5%\n",
            "Epoch2: 133/200 = 66.5%\n",
            "Epoch3: 135/200 = 67.5%\n",
            "Epoch4: 140/200 = 70.0%\n",
            "Epoch5: 133/200 = 66.5%\n",
            "Epoch6: 134/200 = 67.0%\n",
            "Epoch7: 127/200 = 63.5%\n",
            "Epoch8: 136/200 = 68.0%\n",
            "Epoch9: 136/200 = 68.0%\n",
            "Epoch10: 137/200 = 68.5%\n",
            "Epoch11: 135/200 = 67.5%\n",
            "Epoch12: 133/200 = 66.5%\n",
            "Epoch13: 133/200 = 66.5%\n",
            "Epoch14: 138/200 = 69.0%\n",
            "Epoch15: 142/200 = 71.0%\n",
            "Epoch16: 139/200 = 69.5%\n",
            "Epoch17: 135/200 = 67.5%\n",
            "Epoch18: 141/200 = 70.5%\n",
            "Epoch19: 139/200 = 69.5%\n",
            "Epoch20: 137/200 = 68.5%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 1.4706072807312012 seconds\n",
            "\n",
            "Round 8 finished...\n",
            "Testing Accuracy for Test Data: 37.0%\n",
            "\n",
            "Epoch1: 140/200 = 70.0%\n",
            "Epoch2: 135/200 = 67.5%\n",
            "Epoch3: 142/200 = 71.0%\n",
            "Epoch4: 136/200 = 68.0%\n",
            "Epoch5: 139/200 = 69.5%\n",
            "Epoch6: 142/200 = 71.0%\n",
            "Epoch7: 139/200 = 69.5%\n",
            "Epoch8: 142/200 = 71.0%\n",
            "Epoch9: 144/200 = 72.0%\n",
            "Epoch10: 139/200 = 69.5%\n",
            "Epoch11: 139/200 = 69.5%\n",
            "Epoch12: 138/200 = 69.0%\n",
            "Epoch13: 143/200 = 71.5%\n",
            "Epoch14: 136/200 = 68.0%\n",
            "Epoch15: 146/200 = 73.0%\n",
            "Epoch16: 144/200 = 72.0%\n",
            "Epoch17: 139/200 = 69.5%\n",
            "Epoch18: 142/200 = 71.0%\n",
            "Epoch19: 144/200 = 72.0%\n",
            "Epoch20: 142/200 = 71.0%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 1.4572651386260986 seconds\n",
            "\n",
            "Round 9 finished...\n",
            "Testing Accuracy for Test Data: 37.85%\n",
            "\n",
            "Epoch1: 140/200 = 70.0%\n",
            "Epoch2: 145/200 = 72.5%\n",
            "Epoch3: 145/200 = 72.5%\n",
            "Epoch4: 146/200 = 73.0%\n",
            "Epoch5: 148/200 = 74.0%\n",
            "Epoch6: 147/200 = 73.5%\n",
            "Epoch7: 147/200 = 73.5%\n",
            "Epoch8: 143/200 = 71.5%\n",
            "Epoch9: 144/200 = 72.0%\n",
            "Epoch10: 150/200 = 75.0%\n",
            "Epoch11: 145/200 = 72.5%\n",
            "Epoch12: 147/200 = 73.5%\n",
            "Epoch13: 150/200 = 75.0%\n",
            "Epoch14: 147/200 = 73.5%\n",
            "Epoch15: 145/200 = 72.5%\n",
            "Epoch16: 148/200 = 74.0%\n",
            "Epoch17: 150/200 = 75.0%\n",
            "Epoch18: 150/200 = 75.0%\n",
            "Epoch19: 154/200 = 77.0%\n",
            "Epoch20: 154/200 = 77.0%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 1.4892749786376953 seconds\n",
            "\n",
            "Round 10 finished...\n",
            "Testing Accuracy for Test Data: 38.1%\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "weights = (random_matrix_generator(HIDDEN_LAYER_SIZE, INPUT_LAYER_SIZE),\n",
        "               random_matrix_generator(HIDDEN_LAYER_SIZE, HIDDEN_LAYER_SIZE),\n",
        "               random_matrix_generator(OUTPUT_LAYER_SIZE, HIDDEN_LAYER_SIZE))\n",
        "biases = (zero_matrix_generator(HIDDEN_LAYER_SIZE, 1),\n",
        "          zero_matrix_generator(HIDDEN_LAYER_SIZE, 1),\n",
        "          zero_matrix_generator(OUTPUT_LAYER_SIZE, 1))\n",
        "\n",
        "total_avg_cost = []\n",
        "for i in range(10):\n",
        "    weights, biases, avg_costs = train_network(train_data[:200], train_data_labels[:200], \n",
        "                                            weights, biases, backpropagation_method=vectorized_backpropagation)\n",
        "    total_avg_cost.append(sum(avg_costs) / len(avg_costs))\n",
        "    print(f'\\nRound {i + 1} finished...')\n",
        "    print(f'Testing Accuracy for Test Data: {test_network(test_data, test_data_labels, weights, biases) * 100}%\\n')\n",
        "\n",
        "plot(range(len(total_avg_cost)), total_avg_cost, 'round', 'avg_loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roOjQ20cn57p"
      },
      "source": [
        "## Fifth Part (Testing the model)\n",
        "Training the model with vectorized backpropagation and testing the trained network. (Using all the existing dataset) <br/>\n",
        "***Important Note :*** Each round contains 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "It-i1p04oKaL",
        "outputId": "e143ba39-ed0d-47d3-a23d-193eee8b5524"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch1: 7860/20000 = 39.300000000000004%\n",
            "Epoch2: 9011/20000 = 45.055%\n",
            "Epoch3: 9487/20000 = 47.435%\n",
            "Epoch4: 9675/20000 = 48.375%\n",
            "Epoch5: 9785/20000 = 48.925000000000004%\n",
            "Epoch6: 9974/20000 = 49.87%\n",
            "Epoch7: 10105/20000 = 50.525%\n",
            "Epoch8: 10179/20000 = 50.895%\n",
            "Epoch9: 10230/20000 = 51.15%\n",
            "Epoch10: 10288/20000 = 51.44%\n",
            "Epoch11: 10453/20000 = 52.26499999999999%\n",
            "Epoch12: 10492/20000 = 52.459999999999994%\n",
            "Epoch13: 10548/20000 = 52.739999999999995%\n",
            "Epoch14: 10574/20000 = 52.87%\n",
            "Epoch15: 10576/20000 = 52.88%\n",
            "Epoch16: 10653/20000 = 53.26499999999999%\n",
            "Epoch17: 10719/20000 = 53.595000000000006%\n",
            "Epoch18: 10723/20000 = 53.615%\n",
            "Epoch19: 10790/20000 = 53.949999999999996%\n",
            "Epoch20: 10773/20000 = 53.864999999999995%\n",
            "Epoch21: 10857/20000 = 54.285000000000004%\n",
            "Epoch22: 10897/20000 = 54.48499999999999%\n",
            "Epoch23: 10941/20000 = 54.705000000000005%\n",
            "Epoch24: 11001/20000 = 55.005%\n",
            "Epoch25: 10948/20000 = 54.74%\n",
            "Epoch26: 11003/20000 = 55.015%\n",
            "Epoch27: 11095/20000 = 55.474999999999994%\n",
            "Epoch28: 10986/20000 = 54.93%\n",
            "Epoch29: 11079/20000 = 55.395%\n",
            "Epoch30: 11128/20000 = 55.64%\n",
            "Epoch31: 11179/20000 = 55.894999999999996%\n",
            "Epoch32: 11162/20000 = 55.81%\n",
            "Epoch33: 11138/20000 = 55.69%\n",
            "Epoch34: 11239/20000 = 56.19499999999999%\n",
            "Epoch35: 11276/20000 = 56.379999999999995%\n",
            "Epoch36: 11253/20000 = 56.265%\n",
            "Epoch37: 11336/20000 = 56.68%\n",
            "Epoch38: 11401/20000 = 57.004999999999995%\n",
            "Epoch39: 11367/20000 = 56.835%\n",
            "Epoch40: 11384/20000 = 56.92%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 274.0782697200775 seconds\n",
            "\n",
            "Round 1 finished...\n",
            "Testing Accuracy for Test Data: 53.400000000000006%\n",
            "\n",
            "Epoch1: 11418/20000 = 57.089999999999996%\n",
            "Epoch2: 11441/20000 = 57.205%\n",
            "Epoch3: 11436/20000 = 57.18%\n",
            "Epoch4: 11463/20000 = 57.315000000000005%\n",
            "Epoch5: 11539/20000 = 57.69499999999999%\n",
            "Epoch6: 11557/20000 = 57.785%\n",
            "Epoch7: 11611/20000 = 58.055%\n",
            "Epoch8: 11583/20000 = 57.915000000000006%\n",
            "Epoch9: 11650/20000 = 58.25%\n",
            "Epoch10: 11641/20000 = 58.205%\n",
            "Epoch11: 11646/20000 = 58.230000000000004%\n",
            "Epoch12: 11728/20000 = 58.64%\n",
            "Epoch13: 11729/20000 = 58.645%\n",
            "Epoch14: 11602/20000 = 58.01%\n",
            "Epoch15: 11739/20000 = 58.695%\n",
            "Epoch16: 11790/20000 = 58.95%\n",
            "Epoch17: 11839/20000 = 59.195%\n",
            "Epoch18: 11765/20000 = 58.825%\n",
            "Epoch19: 11800/20000 = 59.0%\n",
            "Epoch20: 11755/20000 = 58.775%\n",
            "Epoch21: 11813/20000 = 59.065%\n",
            "Epoch22: 11790/20000 = 58.95%\n",
            "Epoch23: 11921/20000 = 59.605%\n",
            "Epoch24: 11896/20000 = 59.48%\n",
            "Epoch25: 11881/20000 = 59.404999999999994%\n",
            "Epoch26: 11910/20000 = 59.550000000000004%\n",
            "Epoch27: 11944/20000 = 59.72%\n",
            "Epoch28: 11926/20000 = 59.63%\n",
            "Epoch29: 11893/20000 = 59.465%\n",
            "Epoch30: 12025/20000 = 60.12499999999999%\n",
            "Epoch31: 11987/20000 = 59.935%\n",
            "Epoch32: 11973/20000 = 59.865%\n",
            "Epoch33: 11963/20000 = 59.815%\n",
            "Epoch34: 11705/20000 = 58.525000000000006%\n",
            "Epoch35: 11773/20000 = 58.865%\n",
            "Epoch36: 11790/20000 = 58.95%\n",
            "Epoch37: 11952/20000 = 59.760000000000005%\n",
            "Epoch38: 12116/20000 = 60.58%\n",
            "Epoch39: 12150/20000 = 60.75000000000001%\n",
            "Epoch40: 12105/20000 = 60.525%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 301.8806805610657 seconds\n",
            "\n",
            "Round 2 finished...\n",
            "Testing Accuracy for Test Data: 54.900000000000006%\n",
            "\n",
            "Epoch1: 12115/20000 = 60.575%\n",
            "Epoch2: 12163/20000 = 60.815%\n",
            "Epoch3: 12121/20000 = 60.605%\n",
            "Epoch4: 12163/20000 = 60.815%\n",
            "Epoch5: 12170/20000 = 60.85%\n",
            "Epoch6: 12207/20000 = 61.035%\n",
            "Epoch7: 12212/20000 = 61.06%\n",
            "Epoch8: 12201/20000 = 61.004999999999995%\n",
            "Epoch9: 12203/20000 = 61.015%\n",
            "Epoch10: 12288/20000 = 61.44%\n",
            "Epoch11: 12253/20000 = 61.265%\n",
            "Epoch12: 12266/20000 = 61.33%\n",
            "Epoch13: 12207/20000 = 61.035%\n",
            "Epoch14: 12191/20000 = 60.955000000000005%\n",
            "Epoch15: 12277/20000 = 61.385%\n",
            "Epoch16: 12242/20000 = 61.21%\n",
            "Epoch17: 12268/20000 = 61.339999999999996%\n",
            "Epoch18: 12262/20000 = 61.309999999999995%\n",
            "Epoch19: 12301/20000 = 61.504999999999995%\n",
            "Epoch20: 12307/20000 = 61.535%\n",
            "Epoch21: 12356/20000 = 61.78%\n",
            "Epoch22: 12356/20000 = 61.78%\n",
            "Epoch23: 12366/20000 = 61.83%\n",
            "Epoch24: 12247/20000 = 61.23499999999999%\n",
            "Epoch25: 12395/20000 = 61.975%\n",
            "Epoch26: 12386/20000 = 61.92999999999999%\n",
            "Epoch27: 12365/20000 = 61.824999999999996%\n",
            "Epoch28: 12420/20000 = 62.1%\n",
            "Epoch29: 12428/20000 = 62.13999999999999%\n",
            "Epoch30: 12414/20000 = 62.07%\n",
            "Epoch31: 12394/20000 = 61.970000000000006%\n",
            "Epoch32: 12430/20000 = 62.150000000000006%\n",
            "Epoch33: 12446/20000 = 62.23%\n",
            "Epoch34: 12433/20000 = 62.165000000000006%\n",
            "Epoch35: 12467/20000 = 62.334999999999994%\n",
            "Epoch36: 12496/20000 = 62.480000000000004%\n",
            "Epoch37: 12464/20000 = 62.32%\n",
            "Epoch38: 12457/20000 = 62.285000000000004%\n",
            "Epoch39: 12523/20000 = 62.614999999999995%\n",
            "Epoch40: 12545/20000 = 62.724999999999994%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 275.29892444610596 seconds\n",
            "\n",
            "Round 3 finished...\n",
            "Testing Accuracy for Test Data: 55.35%\n",
            "\n",
            "Epoch1: 12506/20000 = 62.529999999999994%\n",
            "Epoch2: 12458/20000 = 62.29%\n",
            "Epoch3: 12529/20000 = 62.644999999999996%\n",
            "Epoch4: 12556/20000 = 62.78%\n",
            "Epoch5: 12605/20000 = 63.025%\n",
            "Epoch6: 12562/20000 = 62.81%\n",
            "Epoch7: 12631/20000 = 63.154999999999994%\n",
            "Epoch8: 12515/20000 = 62.575%\n",
            "Epoch9: 12548/20000 = 62.739999999999995%\n",
            "Epoch10: 12599/20000 = 62.995000000000005%\n",
            "Epoch11: 12558/20000 = 62.79%\n",
            "Epoch12: 12609/20000 = 63.044999999999995%\n",
            "Epoch13: 12657/20000 = 63.285000000000004%\n",
            "Epoch14: 12660/20000 = 63.3%\n",
            "Epoch15: 12685/20000 = 63.425%\n",
            "Epoch16: 12682/20000 = 63.41%\n",
            "Epoch17: 12690/20000 = 63.449999999999996%\n",
            "Epoch18: 12606/20000 = 63.029999999999994%\n",
            "Epoch19: 12677/20000 = 63.385000000000005%\n",
            "Epoch20: 12692/20000 = 63.46000000000001%\n",
            "Epoch21: 12648/20000 = 63.239999999999995%\n",
            "Epoch22: 12648/20000 = 63.239999999999995%\n",
            "Epoch23: 12632/20000 = 63.160000000000004%\n",
            "Epoch24: 12696/20000 = 63.480000000000004%\n",
            "Epoch25: 12689/20000 = 63.44499999999999%\n",
            "Epoch26: 12721/20000 = 63.605000000000004%\n",
            "Epoch27: 12695/20000 = 63.475%\n",
            "Epoch28: 12704/20000 = 63.519999999999996%\n",
            "Epoch29: 12739/20000 = 63.695%\n",
            "Epoch30: 12689/20000 = 63.44499999999999%\n",
            "Epoch31: 12699/20000 = 63.495000000000005%\n",
            "Epoch32: 12807/20000 = 64.035%\n",
            "Epoch33: 12763/20000 = 63.815%\n",
            "Epoch34: 12779/20000 = 63.895%\n",
            "Epoch35: 12735/20000 = 63.675000000000004%\n",
            "Epoch36: 12767/20000 = 63.834999999999994%\n",
            "Epoch37: 12766/20000 = 63.83%\n",
            "Epoch38: 12845/20000 = 64.225%\n",
            "Epoch39: 12763/20000 = 63.815%\n",
            "Epoch40: 12805/20000 = 64.025%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 273.78472995758057 seconds\n",
            "\n",
            "Round 4 finished...\n",
            "Testing Accuracy for Test Data: 54.65%\n",
            "\n",
            "Epoch1: 12815/20000 = 64.075%\n",
            "Epoch2: 12846/20000 = 64.23%\n",
            "Epoch3: 12833/20000 = 64.165%\n",
            "Epoch4: 12825/20000 = 64.125%\n",
            "Epoch5: 12852/20000 = 64.25999999999999%\n",
            "Epoch6: 12849/20000 = 64.24499999999999%\n",
            "Epoch7: 12862/20000 = 64.31%\n",
            "Epoch8: 12736/20000 = 63.68000000000001%\n",
            "Epoch9: 12865/20000 = 64.325%\n",
            "Epoch10: 12885/20000 = 64.425%\n",
            "Epoch11: 12900/20000 = 64.5%\n",
            "Epoch12: 12869/20000 = 64.345%\n",
            "Epoch13: 12909/20000 = 64.545%\n",
            "Epoch14: 12896/20000 = 64.48%\n",
            "Epoch15: 12948/20000 = 64.74%\n",
            "Epoch16: 12804/20000 = 64.02%\n",
            "Epoch17: 12864/20000 = 64.32%\n",
            "Epoch18: 12901/20000 = 64.505%\n",
            "Epoch19: 12941/20000 = 64.705%\n",
            "Epoch20: 12934/20000 = 64.67%\n",
            "Epoch21: 12893/20000 = 64.46499999999999%\n",
            "Epoch22: 12889/20000 = 64.445%\n",
            "Epoch23: 12876/20000 = 64.38000000000001%\n",
            "Epoch24: 12994/20000 = 64.97%\n",
            "Epoch25: 12979/20000 = 64.895%\n",
            "Epoch26: 13008/20000 = 65.03999999999999%\n",
            "Epoch27: 12955/20000 = 64.775%\n",
            "Epoch28: 12989/20000 = 64.945%\n",
            "Epoch29: 12995/20000 = 64.97500000000001%\n",
            "Epoch30: 12969/20000 = 64.845%\n",
            "Epoch31: 12948/20000 = 64.74%\n",
            "Epoch32: 12924/20000 = 64.62%\n",
            "Epoch33: 12938/20000 = 64.69%\n",
            "Epoch34: 13013/20000 = 65.065%\n",
            "Epoch35: 13008/20000 = 65.03999999999999%\n",
            "Epoch36: 12981/20000 = 64.905%\n",
            "Epoch37: 13112/20000 = 65.56%\n",
            "Epoch38: 13088/20000 = 65.44%\n",
            "Epoch39: 13086/20000 = 65.42999999999999%\n",
            "Epoch40: 12929/20000 = 64.645%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 279.10309076309204 seconds\n",
            "\n",
            "Round 5 finished...\n",
            "Testing Accuracy for Test Data: 54.7%\n",
            "\n",
            "Epoch1: 13078/20000 = 65.39%\n",
            "Epoch2: 13066/20000 = 65.33%\n",
            "Epoch3: 13044/20000 = 65.22%\n",
            "Epoch4: 13092/20000 = 65.46%\n",
            "Epoch5: 13111/20000 = 65.55499999999999%\n",
            "Epoch6: 13084/20000 = 65.42%\n",
            "Epoch7: 13118/20000 = 65.59%\n",
            "Epoch8: 12998/20000 = 64.99000000000001%\n",
            "Epoch9: 13108/20000 = 65.53999999999999%\n",
            "Epoch10: 13154/20000 = 65.77%\n",
            "Epoch11: 13135/20000 = 65.675%\n",
            "Epoch12: 13112/20000 = 65.56%\n",
            "Epoch13: 13055/20000 = 65.275%\n",
            "Epoch14: 13214/20000 = 66.07%\n",
            "Epoch15: 13087/20000 = 65.435%\n",
            "Epoch16: 13065/20000 = 65.325%\n",
            "Epoch17: 13166/20000 = 65.83%\n",
            "Epoch18: 13219/20000 = 66.095%\n",
            "Epoch19: 13149/20000 = 65.745%\n",
            "Epoch20: 13179/20000 = 65.89500000000001%\n",
            "Epoch21: 13206/20000 = 66.03%\n",
            "Epoch22: 13186/20000 = 65.93%\n",
            "Epoch23: 13232/20000 = 66.16%\n",
            "Epoch24: 13191/20000 = 65.955%\n",
            "Epoch25: 13197/20000 = 65.985%\n",
            "Epoch26: 13235/20000 = 66.175%\n",
            "Epoch27: 13226/20000 = 66.13%\n",
            "Epoch28: 13093/20000 = 65.46499999999999%\n",
            "Epoch29: 13167/20000 = 65.835%\n",
            "Epoch30: 13145/20000 = 65.725%\n",
            "Epoch31: 13241/20000 = 66.205%\n",
            "Epoch32: 13270/20000 = 66.35%\n",
            "Epoch33: 13177/20000 = 65.885%\n",
            "Epoch34: 13221/20000 = 66.105%\n",
            "Epoch35: 13219/20000 = 66.095%\n",
            "Epoch36: 13191/20000 = 65.955%\n",
            "Epoch37: 13302/20000 = 66.51%\n",
            "Epoch38: 13268/20000 = 66.34%\n",
            "Epoch39: 13221/20000 = 66.105%\n",
            "Epoch40: 13332/20000 = 66.66%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 310.49943947792053 seconds\n",
            "\n",
            "Round 6 finished...\n",
            "Testing Accuracy for Test Data: 55.85%\n",
            "\n",
            "Epoch1: 13306/20000 = 66.53%\n",
            "Epoch2: 13243/20000 = 66.215%\n",
            "Epoch3: 13239/20000 = 66.19500000000001%\n",
            "Epoch4: 13327/20000 = 66.635%\n",
            "Epoch5: 13142/20000 = 65.71000000000001%\n",
            "Epoch6: 13356/20000 = 66.78%\n",
            "Epoch7: 13331/20000 = 66.655%\n",
            "Epoch8: 13290/20000 = 66.45%\n",
            "Epoch9: 13371/20000 = 66.855%\n",
            "Epoch10: 13329/20000 = 66.645%\n",
            "Epoch11: 13308/20000 = 66.53999999999999%\n",
            "Epoch12: 13273/20000 = 66.365%\n",
            "Epoch13: 13325/20000 = 66.625%\n",
            "Epoch14: 13363/20000 = 66.815%\n",
            "Epoch15: 13320/20000 = 66.60000000000001%\n",
            "Epoch16: 13355/20000 = 66.77499999999999%\n",
            "Epoch17: 13406/20000 = 67.03%\n",
            "Epoch18: 13338/20000 = 66.69%\n",
            "Epoch19: 13384/20000 = 66.92%\n",
            "Epoch20: 13409/20000 = 67.045%\n",
            "Epoch21: 13365/20000 = 66.825%\n",
            "Epoch22: 13403/20000 = 67.015%\n",
            "Epoch23: 13360/20000 = 66.8%\n",
            "Epoch24: 13412/20000 = 67.06%\n",
            "Epoch25: 13324/20000 = 66.62%\n",
            "Epoch26: 13387/20000 = 66.935%\n",
            "Epoch27: 13442/20000 = 67.21000000000001%\n",
            "Epoch28: 13423/20000 = 67.11500000000001%\n",
            "Epoch29: 13450/20000 = 67.25%\n",
            "Epoch30: 13467/20000 = 67.335%\n",
            "Epoch31: 13425/20000 = 67.125%\n",
            "Epoch32: 13425/20000 = 67.125%\n",
            "Epoch33: 13409/20000 = 67.045%\n",
            "Epoch34: 13428/20000 = 67.14%\n",
            "Epoch35: 13452/20000 = 67.25999999999999%\n",
            "Epoch36: 13382/20000 = 66.91%\n",
            "Epoch37: 13450/20000 = 67.25%\n",
            "Epoch38: 13417/20000 = 67.085%\n",
            "Epoch39: 13457/20000 = 67.285%\n",
            "Epoch40: 13473/20000 = 67.365%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 276.1404402256012 seconds\n",
            "\n",
            "Round 7 finished...\n",
            "Testing Accuracy for Test Data: 55.025%\n",
            "\n",
            "Epoch1: 13472/20000 = 67.36%\n",
            "Epoch2: 13452/20000 = 67.25999999999999%\n",
            "Epoch3: 13468/20000 = 67.34%\n",
            "Epoch4: 13524/20000 = 67.62%\n",
            "Epoch5: 13449/20000 = 67.245%\n",
            "Epoch6: 13476/20000 = 67.38%\n",
            "Epoch7: 13517/20000 = 67.585%\n",
            "Epoch8: 13484/20000 = 67.42%\n",
            "Epoch9: 13434/20000 = 67.17%\n",
            "Epoch10: 13537/20000 = 67.685%\n",
            "Epoch11: 13522/20000 = 67.61%\n",
            "Epoch12: 13510/20000 = 67.55%\n",
            "Epoch13: 13549/20000 = 67.745%\n",
            "Epoch14: 13526/20000 = 67.63%\n",
            "Epoch15: 13526/20000 = 67.63%\n",
            "Epoch16: 13508/20000 = 67.54%\n",
            "Epoch17: 13510/20000 = 67.55%\n",
            "Epoch18: 13571/20000 = 67.855%\n",
            "Epoch19: 13448/20000 = 67.24%\n",
            "Epoch20: 13532/20000 = 67.66%\n",
            "Epoch21: 13565/20000 = 67.825%\n",
            "Epoch22: 13526/20000 = 67.63%\n",
            "Epoch23: 13544/20000 = 67.72%\n",
            "Epoch24: 13516/20000 = 67.58%\n",
            "Epoch25: 13508/20000 = 67.54%\n",
            "Epoch26: 13576/20000 = 67.88%\n",
            "Epoch27: 13490/20000 = 67.45%\n",
            "Epoch28: 13572/20000 = 67.86%\n",
            "Epoch29: 13614/20000 = 68.07%\n",
            "Epoch30: 13518/20000 = 67.58999999999999%\n",
            "Epoch31: 13605/20000 = 68.025%\n",
            "Epoch32: 13584/20000 = 67.92%\n",
            "Epoch33: 13558/20000 = 67.78999999999999%\n",
            "Epoch34: 13527/20000 = 67.635%\n",
            "Epoch35: 13547/20000 = 67.735%\n",
            "Epoch36: 13597/20000 = 67.985%\n",
            "Epoch37: 13593/20000 = 67.965%\n",
            "Epoch38: 13620/20000 = 68.10000000000001%\n",
            "Epoch39: 13586/20000 = 67.93%\n",
            "Epoch40: 13630/20000 = 68.15%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 278.3092577457428 seconds\n",
            "\n",
            "Round 8 finished...\n",
            "Testing Accuracy for Test Data: 54.65%\n",
            "\n",
            "Epoch1: 13622/20000 = 68.11%\n",
            "Epoch2: 13572/20000 = 67.86%\n",
            "Epoch3: 13247/20000 = 66.235%\n",
            "Epoch4: 13096/20000 = 65.48%\n",
            "Epoch5: 13025/20000 = 65.125%\n",
            "Epoch6: 13130/20000 = 65.64999999999999%\n",
            "Epoch7: 13124/20000 = 65.62%\n",
            "Epoch8: 13265/20000 = 66.325%\n",
            "Epoch9: 13163/20000 = 65.815%\n",
            "Epoch10: 13210/20000 = 66.05%\n",
            "Epoch11: 13142/20000 = 65.71000000000001%\n",
            "Epoch12: 13117/20000 = 65.58500000000001%\n",
            "Epoch13: 13217/20000 = 66.08500000000001%\n",
            "Epoch14: 13138/20000 = 65.69%\n",
            "Epoch15: 13208/20000 = 66.03999999999999%\n",
            "Epoch16: 13279/20000 = 66.39500000000001%\n",
            "Epoch17: 13228/20000 = 66.14%\n",
            "Epoch18: 13216/20000 = 66.08000000000001%\n",
            "Epoch19: 13234/20000 = 66.17%\n",
            "Epoch20: 13265/20000 = 66.325%\n",
            "Epoch21: 13260/20000 = 66.3%\n",
            "Epoch22: 13252/20000 = 66.25999999999999%\n",
            "Epoch23: 13237/20000 = 66.185%\n",
            "Epoch24: 13267/20000 = 66.335%\n",
            "Epoch25: 13278/20000 = 66.39%\n",
            "Epoch26: 13263/20000 = 66.315%\n",
            "Epoch27: 13304/20000 = 66.52%\n",
            "Epoch28: 13318/20000 = 66.59%\n",
            "Epoch29: 13228/20000 = 66.14%\n",
            "Epoch30: 13220/20000 = 66.10000000000001%\n",
            "Epoch31: 12857/20000 = 64.285%\n",
            "Epoch32: 12616/20000 = 63.080000000000005%\n",
            "Epoch33: 12753/20000 = 63.76500000000001%\n",
            "Epoch34: 12819/20000 = 64.095%\n",
            "Epoch35: 12793/20000 = 63.965%\n",
            "Epoch36: 12871/20000 = 64.35499999999999%\n",
            "Epoch37: 12875/20000 = 64.375%\n",
            "Epoch38: 12824/20000 = 64.12%\n",
            "Epoch39: 12814/20000 = 64.07000000000001%\n",
            "Epoch40: 12895/20000 = 64.47500000000001%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 280.2876572608948 seconds\n",
            "\n",
            "Round 9 finished...\n",
            "Testing Accuracy for Test Data: 52.400000000000006%\n",
            "\n",
            "Epoch1: 12893/20000 = 64.46499999999999%\n",
            "Epoch2: 12943/20000 = 64.715%\n",
            "Epoch3: 12950/20000 = 64.75%\n",
            "Epoch4: 12911/20000 = 64.55499999999999%\n",
            "Epoch5: 12940/20000 = 64.7%\n",
            "Epoch6: 12854/20000 = 64.27000000000001%\n",
            "Epoch7: 12929/20000 = 64.645%\n",
            "Epoch8: 12970/20000 = 64.85%\n",
            "Epoch9: 12932/20000 = 64.66%\n",
            "Epoch10: 13027/20000 = 65.135%\n",
            "Epoch11: 12919/20000 = 64.595%\n",
            "Epoch12: 12994/20000 = 64.97%\n",
            "Epoch13: 12967/20000 = 64.835%\n",
            "Epoch14: 13033/20000 = 65.16499999999999%\n",
            "Epoch15: 12998/20000 = 64.99000000000001%\n",
            "Epoch16: 13035/20000 = 65.17500000000001%\n",
            "Epoch17: 13035/20000 = 65.17500000000001%\n",
            "Epoch18: 13065/20000 = 65.325%\n",
            "Epoch19: 13026/20000 = 65.13%\n",
            "Epoch20: 13070/20000 = 65.35%\n",
            "Epoch21: 13049/20000 = 65.245%\n",
            "Epoch22: 13074/20000 = 65.36999999999999%\n",
            "Epoch23: 13142/20000 = 65.71000000000001%\n",
            "Epoch24: 13127/20000 = 65.635%\n",
            "Epoch25: 13095/20000 = 65.47500000000001%\n",
            "Epoch26: 13098/20000 = 65.49000000000001%\n",
            "Epoch27: 13059/20000 = 65.295%\n",
            "Epoch28: 13178/20000 = 65.89%\n",
            "Epoch29: 13111/20000 = 65.55499999999999%\n",
            "Epoch30: 13133/20000 = 65.66499999999999%\n",
            "Epoch31: 13167/20000 = 65.835%\n",
            "Epoch32: 13068/20000 = 65.34%\n",
            "Epoch33: 12956/20000 = 64.78%\n",
            "Epoch34: 12822/20000 = 64.11%\n",
            "Epoch35: 12799/20000 = 63.995000000000005%\n",
            "Epoch36: 12891/20000 = 64.455%\n",
            "Epoch37: 12877/20000 = 64.385%\n",
            "Epoch38: 12933/20000 = 64.66499999999999%\n",
            "Epoch39: 12935/20000 = 64.67500000000001%\n",
            "Epoch40: 12943/20000 = 64.715%\n",
            "\n",
            "Training is finished...\n",
            "Time taken for training: 301.2915418148041 seconds\n",
            "\n",
            "Round 10 finished...\n",
            "Testing Accuracy for Test Data: 52.675000000000004%\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "EPOCHS = 40\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "weights = (random_matrix_generator(HIDDEN_LAYER_SIZE, INPUT_LAYER_SIZE),\n",
        "               random_matrix_generator(HIDDEN_LAYER_SIZE, HIDDEN_LAYER_SIZE),\n",
        "               random_matrix_generator(OUTPUT_LAYER_SIZE, HIDDEN_LAYER_SIZE))\n",
        "biases = (zero_matrix_generator(HIDDEN_LAYER_SIZE, 1),\n",
        "          zero_matrix_generator(HIDDEN_LAYER_SIZE, 1),\n",
        "          zero_matrix_generator(OUTPUT_LAYER_SIZE, 1))\n",
        "\n",
        "total_avg_cost = []\n",
        "for i in range(10):\n",
        "    weights, biases, avg_costs = train_network(train_data, train_data_labels, \n",
        "                                            weights, biases, backpropagation_method=vectorized_backpropagation)\n",
        "    total_avg_cost.append(sum(avg_costs) / len(avg_costs))\n",
        "    print(f'\\nRound {i + 1} finished...')\n",
        "    print(f'Testing Accuracy for Test Data: {test_network(test_data, test_data_labels, weights, biases) * 100}%\\n')\n",
        "\n",
        "plot(range(len(total_avg_cost)), total_avg_cost, 'round', 'avg_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UNZCV2AtkHh",
        "outputId": "f29036f8-487c-4e88-9f3c-911079e483fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 52.675000000000004%\n"
          ]
        }
      ],
      "source": [
        "print(f'Testing Accuracy: {test_network(test_data, test_data_labels, weights, biases) * 100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMmrv1E9wEGU"
      },
      "source": [
        "## Bonus Part\n",
        "Creating a CNN using keras to solve the problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIQtF5ejwN2k",
        "outputId": "83da84a5-9738-4834-f189-6d4598ff607f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, losses\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XInHmAQEWu2d"
      },
      "source": [
        "Training without batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti8ORuIayGVq",
        "outputId": "083ba3ec-1abd-4712-e5dd-7d2b2a3ba707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 673,258\n",
            "Trainable params: 673,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([                      \n",
        "    layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Dense(128, kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Dense(64, kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Dense(10, kernel_initializer='he_uniform', activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym2IoNf912ck"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=losses.SparseCategoricalCrossentropy(), \n",
        "              metrics=[\n",
        "                  'accuracy'\n",
        "              ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeJuuhtd3AOv",
        "outputId": "c833f19f-9aa0-4b03-8301-618b8201bb04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3125/3125 [==============================] - 74s 21ms/step - loss: 2.2488 - accuracy: 0.3795 - val_loss: 1.4986 - val_accuracy: 0.4588\n",
            "Epoch 2/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 1.3847 - accuracy: 0.5029 - val_loss: 1.4840 - val_accuracy: 0.4934\n",
            "Epoch 3/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 1.2184 - accuracy: 0.5714 - val_loss: 1.1541 - val_accuracy: 0.6074\n",
            "Epoch 4/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 1.1243 - accuracy: 0.6112 - val_loss: 1.1975 - val_accuracy: 0.5993\n",
            "Epoch 5/20\n",
            "3125/3125 [==============================] - 67s 21ms/step - loss: 1.0480 - accuracy: 0.6418 - val_loss: 1.0459 - val_accuracy: 0.6523\n",
            "Epoch 6/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.9765 - accuracy: 0.6671 - val_loss: 1.0192 - val_accuracy: 0.6529\n",
            "Epoch 7/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.9282 - accuracy: 0.6840 - val_loss: 1.0621 - val_accuracy: 0.6553\n",
            "Epoch 8/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.8839 - accuracy: 0.7044 - val_loss: 1.0121 - val_accuracy: 0.6733\n",
            "Epoch 9/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.8499 - accuracy: 0.7180 - val_loss: 1.0429 - val_accuracy: 0.6656\n",
            "Epoch 10/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.8152 - accuracy: 0.7292 - val_loss: 0.9814 - val_accuracy: 0.6880\n",
            "Epoch 11/20\n",
            "3125/3125 [==============================] - 68s 22ms/step - loss: 0.7938 - accuracy: 0.7365 - val_loss: 0.8801 - val_accuracy: 0.7111\n",
            "Epoch 12/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.7547 - accuracy: 0.7507 - val_loss: 0.9670 - val_accuracy: 0.6961\n",
            "Epoch 13/20\n",
            "3125/3125 [==============================] - 68s 22ms/step - loss: 0.7439 - accuracy: 0.7556 - val_loss: 0.9162 - val_accuracy: 0.7098\n",
            "Epoch 14/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.6999 - accuracy: 0.7701 - val_loss: 0.9572 - val_accuracy: 0.7116\n",
            "Epoch 15/20\n",
            "3125/3125 [==============================] - 68s 22ms/step - loss: 0.7159 - accuracy: 0.7673 - val_loss: 0.8533 - val_accuracy: 0.7252\n",
            "Epoch 16/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.6810 - accuracy: 0.7764 - val_loss: 0.9547 - val_accuracy: 0.6965\n",
            "Epoch 17/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.6671 - accuracy: 0.7834 - val_loss: 0.8897 - val_accuracy: 0.7232\n",
            "Epoch 18/20\n",
            "3125/3125 [==============================] - 68s 22ms/step - loss: 0.6604 - accuracy: 0.7877 - val_loss: 0.9174 - val_accuracy: 0.7272\n",
            "Epoch 19/20\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.6325 - accuracy: 0.7984 - val_loss: 1.0113 - val_accuracy: 0.6966\n",
            "Epoch 20/20\n",
            "3125/3125 [==============================] - 68s 22ms/step - loss: 0.6802 - accuracy: 0.7838 - val_loss: 0.9925 - val_accuracy: 0.7164\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train, batch_size=16, epochs=20, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foVbAzGUW6RG"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([                      \n",
        "    layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(128, kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Dense(64, kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Dense(10, kernel_initializer='he_uniform', activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNNlhYKLXU88"
      },
      "source": [
        "After using batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX1nR7VaXHkp",
        "outputId": "420f8a96-0152-4704-b0e0-045c61c272de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3125/3125 [==============================] - 77s 24ms/step - loss: 1.5289 - accuracy: 0.4483 - val_loss: 1.1457 - val_accuracy: 0.5966\n",
            "Epoch 2/20\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 1.0084 - accuracy: 0.6498 - val_loss: 1.0018 - val_accuracy: 0.6536\n",
            "Epoch 3/20\n",
            "3125/3125 [==============================] - 77s 25ms/step - loss: 0.7845 - accuracy: 0.7339 - val_loss: 0.7117 - val_accuracy: 0.7573\n",
            "Epoch 4/20\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.6491 - accuracy: 0.7797 - val_loss: 0.7239 - val_accuracy: 0.7550\n",
            "Epoch 5/20\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.5481 - accuracy: 0.8140 - val_loss: 0.6554 - val_accuracy: 0.7809\n",
            "Epoch 6/20\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.4728 - accuracy: 0.8430 - val_loss: 0.5966 - val_accuracy: 0.8011\n",
            "Epoch 7/20\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.4066 - accuracy: 0.8641 - val_loss: 0.6269 - val_accuracy: 0.8005\n",
            "Epoch 8/20\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.3434 - accuracy: 0.8859 - val_loss: 0.6043 - val_accuracy: 0.8101\n",
            "Epoch 9/20\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.3006 - accuracy: 0.8992 - val_loss: 0.6630 - val_accuracy: 0.8017\n",
            "Epoch 10/20\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.2607 - accuracy: 0.9128 - val_loss: 0.7180 - val_accuracy: 0.7975\n",
            "Epoch 11/20\n",
            "3125/3125 [==============================] - 77s 25ms/step - loss: 0.2258 - accuracy: 0.9240 - val_loss: 0.6327 - val_accuracy: 0.8172\n",
            "Epoch 12/20\n",
            "3125/3125 [==============================] - 77s 25ms/step - loss: 0.1986 - accuracy: 0.9341 - val_loss: 0.7049 - val_accuracy: 0.8103\n",
            "Epoch 13/20\n",
            "3125/3125 [==============================] - 77s 24ms/step - loss: 0.1755 - accuracy: 0.9410 - val_loss: 0.7775 - val_accuracy: 0.8093\n",
            "Epoch 14/20\n",
            "3125/3125 [==============================] - 77s 25ms/step - loss: 0.1645 - accuracy: 0.9450 - val_loss: 0.7691 - val_accuracy: 0.8120\n",
            "Epoch 15/20\n",
            "3125/3125 [==============================] - 77s 25ms/step - loss: 0.1489 - accuracy: 0.9503 - val_loss: 0.7051 - val_accuracy: 0.8216\n",
            "Epoch 16/20\n",
            "3125/3125 [==============================] - 76s 24ms/step - loss: 0.1332 - accuracy: 0.9551 - val_loss: 0.7177 - val_accuracy: 0.8203\n",
            "Epoch 17/20\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.1249 - accuracy: 0.9578 - val_loss: 0.7345 - val_accuracy: 0.8163\n",
            "Epoch 18/20\n",
            "3125/3125 [==============================] - 77s 25ms/step - loss: 0.1163 - accuracy: 0.9617 - val_loss: 0.7664 - val_accuracy: 0.8227\n",
            "Epoch 19/20\n",
            "3125/3125 [==============================] - 78s 25ms/step - loss: 0.1039 - accuracy: 0.9654 - val_loss: 0.7883 - val_accuracy: 0.8187\n",
            "Epoch 20/20\n",
            "3125/3125 [==============================] - 77s 25ms/step - loss: 0.0997 - accuracy: 0.9671 - val_loss: 0.8018 - val_accuracy: 0.8156\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss=losses.SparseCategoricalCrossentropy(), \n",
        "              metrics=[\n",
        "                  'accuracy'\n",
        "              ])\n",
        "history = model.fit(x_train, y_train, batch_size=16, epochs=20, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53tZvazLZnaW"
      },
      "source": [
        "Adding Dropout to the CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNsgqYVKZkjh",
        "outputId": "8b731acf-1526-47c5-8ec8-77a22972c2b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 4, 4, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 2, 2, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 675,178\n",
            "Trainable params: 674,218\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([                      \n",
        "    layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(128, kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(64, kernel_initializer='he_uniform', activation='relu'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(10, kernel_initializer='he_uniform', activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3FnVghKaXGm",
        "outputId": "78d90f9b-f201-451a-f39d-21a0553f8702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss=losses.SparseCategoricalCrossentropy(), \n",
        "              metrics=[\n",
        "                  'accuracy'\n",
        "              ])\n",
        "history = model.fit(x_train, y_train, batch_size=16, epochs=20, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agx8ERPot09Z"
      },
      "source": [
        "Showing Recall, Precision and F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdFgCgDnuBsO"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(x_test, batch_size=32, verbose=1)\n",
        "predicted = np.argmax(prediction, axis=1)\n",
        "\n",
        "print(f'Precision: {precision_score(y_test, predicted, average=\"weighted\")}')\n",
        "print(f'Recall: {recall_score(y_test, predicted, average=\"weighted\")}')\n",
        "print(f'F1: {f1_score(y_test, predicted, average=\"weighted\")}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD1mHu4TxsCY"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  output = model.predict(np.array([x_test[i]]))\n",
        "  print(i+1, ' : ', classes[np.argmax(output)])\n",
        "  plt.imshow(x_test[i])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NeuralNetwork.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}